---
title: "CMOS Image Sensor Quality Analysis"
excerpt: "ðŸ“… **Jun. 2015 - Sep. 2016** <br/> Developed a suite of tools to analyze image sensor quality. Depicts the sensorsâ€™ silicon wafer with indications of areas with the most unstable sensor chips. Also provides functions like history recording, re/undo, statistics calculation, pixel editing, and image transformations, behind a user-friendly GUI. [More info.](https://b7leung.github.io/projects/image-sensor-reader/) <br/><img src='/images/image_sensor_Main_Picture.jpg'>"
collection: projects
redirect_from: 
  - /image-sensor-reader/
---

ðŸ“… **Jun. 2015 - Sep. 2016** â€¢ <img src="/images/github_icon.png" width="20" height="20"> [Github](https://github.com/b7leung/CMOS-Raw-Image-Reader)

<img src='/images/image_sensor_Main_Picture.jpg'>

In this project, we focus on studying two classical reinforcement learning algorithms: Q-learning and Monte-Carlo
policy iteration. These techniques are applied to a two-player game called Connect Four, which is a game similar
to tic-tac-toe, in order to learn a policy which will allow an AI agent to play the game at a high level. In Section 2,
we formally describe the game as an MDP. Then, in Section 3 we describe our RL algorithms and how it can be
applied to the MDP formulation. This includes the generation of episodes using self-play, which we will use to
update our policy. Finally, in Section 4 the final results are presented on a variety of different opponents. We also
give some insight into the affect of various parameters and give some visualizations of the results.

